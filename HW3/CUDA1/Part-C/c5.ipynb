{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh2_iYX9M6l0",
        "outputId": "f2681b43-29a5-409b-ce31-c6d622a41903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "# Installing needed package (triton)\n",
        "! pip install triton"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing needed libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import triton\n",
        "import triton.language as tl\n",
        "import time"
      ],
      "metadata": {
        "id": "xrqCL5oJNYtM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Golbal Variables\n",
        "DEVICE = \"cuda\"\n",
        "C_OUT = 64\n",
        "C_IN = 3\n",
        "H = 1024\n",
        "W = 1024\n",
        "FH = 3\n",
        "FW = 3"
      ],
      "metadata": {
        "id": "E4DKrlpWNbKk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making torch tensors\n",
        "tensor_I = torch.rand(1, C_IN, H, W, device=DEVICE) # Input, assuming that batch_size is one\n",
        "tensor_F = torch.rand(C_OUT, C_IN, FH, FW , device=DEVICE) # Weights"
      ],
      "metadata": {
        "id": "GmUlLgAqNhoC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the result from Convolutional Layer provided by Torch\n",
        "# Use this for correctness check\n",
        "golden_out = F.conv2d(tensor_I, tensor_F, padding=1)\n",
        "print(golden_out.shape) # (1, C_OUT, OUT_H, OUT_W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_wodsTiNd7s",
        "outputId": "6a41b223-e5c6-4b5c-9418-e9b132b1246d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 1024, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def my_triton_kernel(\n",
        "    input_channels, input_height, input_width, num_filters, padding, filter_height, filter_width, input, filter, output,\n",
        "    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr\n",
        "):\n",
        "    \"\"\"\n",
        "  This is a triton kernel that does Conv assuming that padding=1, stride=1\n",
        "  You should 1) load the values fro input and kernel, 2) does computation, 3) store the result\n",
        "  \"\"\"\n",
        "  # TODO: Complete the triton kernel that does convolution\n",
        "    tx = tl.program_id(0)\n",
        "    ty = tl.program_id(1)\n",
        "    tz = tl.program_id(2)\n",
        "\n",
        "    result = 0.0\n",
        "    for channel in range(0, input_channels):\n",
        "        for row in range(filter_height):\n",
        "            for col in range(filter_width):\n",
        "                x = tx + col\n",
        "                y = ty + row\n",
        "\n",
        "                i_idx = channel * (input_height + 2 * padding) * (input_width + 2 * padding)\n",
        "                i_idx += y * (input_width + 2 * padding)\n",
        "                i_idx += x\n",
        "\n",
        "\n",
        "                f_idx = tz * input_channels * filter_height * filter_width\n",
        "                f_idx += channel * filter_height * filter_width\n",
        "                f_idx += row * filter_width + col\n",
        "\n",
        "                load_i = input + i_idx\n",
        "                load_f = filter + f_idx\n",
        "\n",
        "                result += tl.load(load_i) * tl.load(load_f)\n",
        "\n",
        "    o_idx = tz * input_height * input_width\n",
        "    o_idx += ty * input_width\n",
        "    o_idx += tx\n",
        "    out = output + o_idx\n",
        "    tl.store(out, result)\n",
        "\n",
        "\n",
        "def my_conv2d(input, kernel):\n",
        "    \"\"\"\n",
        "    This function is a wrapper function that preprocess the inputs and call the kernel\n",
        "    input: torch.tensor (1, C_IN, H, W)\n",
        "    kernel: torch.tensor (C_OUT, C_IN, FH, FW)\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Initializing some variables\n",
        "\n",
        "    nothing, input_channels, input_height, input_width = input.shape\n",
        "    output_channels, nothing, filter_height, filter_width = kernel.shape\n",
        "    padding = int(filter_height / 2)\n",
        "\n",
        "    device = \"cuda\"\n",
        "\n",
        "    input = input.to(dtype=torch.float32)\n",
        "    kernel = kernel.to(dtype=torch.float32)\n",
        "\n",
        "    input_with_padding = torch.nn.functional.pad(input, (padding, padding, padding, padding))\n",
        "\n",
        "    # TODO: Calculate output dimension & Allocate output tensor\n",
        "\n",
        "    output = torch.empty((1, output_channels, input_height, input_width), device=device, dtype=torch.float32)\n",
        "\n",
        "    tri_i, tri_f, tri_o = input_with_padding.flatten(), kernel.flatten(), output.flatten()\n",
        "\n",
        "    # TODO: Define grid\n",
        "\n",
        "    grid = (input_width, input_height, output_channels)\n",
        "\n",
        "    # TODO: Call the triton kernel (my_triton_kernel) and measure execution time\n",
        "\n",
        "    start = time.time()\n",
        "    my_triton_kernel[grid](\n",
        "        input_channels, input_height, input_width, output_channels, padding,filter_height, filter_width, tri_i, tri_f, tri_o,\n",
        "        BLOCK_H=1, BLOCK_W=1\n",
        "    )\n",
        "    # synchronize to make sure kernel is done\n",
        "    torch.cuda.synchronize()\n",
        "    end = time.time()\n",
        "    exec_time_ms = (end - start)\n",
        "\n",
        "    # TODO: Return output (output should include execution time)\n",
        "\n",
        "    return output, exec_time_ms"
      ],
      "metadata": {
        "id": "cEU8zdqCN_8Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "# Comparing the result from my_conv2d and Conv from torch\n",
        "my_output, execution_time = my_conv2d(tensor_I, tensor_F)\n",
        "torch.testing.assert_close(golden_out, my_output) # Assert statement should be passed\n",
        "# Printing the execution time\n",
        "print(f\"Execution Time for triton kernel (ms): {execution_time * 1000:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YVPpAa0OD4_",
        "outputId": "0b2ea34f-bb0a-44d6-a3de-80a119777277"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time for triton kernel (ms): 1031.304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KTRiPooQTXEs"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}